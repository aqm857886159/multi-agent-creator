"""
æµ‹è¯•æ–°æ”¹è¿›æ¨¡å— - P0/P1/P2/P4

æµ‹è¯•å†…å®¹:
1. P0: PromptManager æç¤ºè¯ç®¡ç†
2. P2: ToolMasker åŠ¨æ€å·¥å…·å±è”½
3. P1: ContextCompressor ä¸Šä¸‹æ–‡å‹ç¼©
4. P4: FeedbackAnalyzer åé¦ˆåˆ†æ
"""

import sys
import os

# ç¡®ä¿ UTF-8 è¾“å‡º
sys.stdout.reconfigure(encoding='utf-8')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def test_prompt_manager():
    """æµ‹è¯• P0: PromptManager"""
    print("\n" + "="*60)
    print("æµ‹è¯• P0: PromptManager")
    print("="*60)
    
    from core.prompt_manager import (
        get_prompt,
        get_role,
        get_goal,
        get_available_tools,
        get_compression_template,
        get_prompt_manager
    )
    
    # æµ‹è¯• 1: è·å–æç¤ºè¯
    print("\n1. æµ‹è¯•è·å–æç¤ºè¯...")
    planner_prompt = get_prompt("planner", "system")
    assert planner_prompt, "Planner prompt ä¸åº”ä¸ºç©º"
    assert "è§„åˆ’å¸ˆ" in planner_prompt or "è°ƒåº¦" in planner_prompt, "Planner prompt åº”åŒ…å«è§’è‰²æè¿°"
    print(f"   âœ“ Planner prompt é•¿åº¦: {len(planner_prompt)} å­—ç¬¦")
    
    # æµ‹è¯• 2: è·å–è§’è‰²å’Œç›®æ ‡
    print("\n2. æµ‹è¯•è·å–è§’è‰²å’Œç›®æ ‡...")
    role = get_role("keyword_designer")
    goal = get_goal("keyword_designer")
    assert role, "Role ä¸åº”ä¸ºç©º"
    assert goal, "Goal ä¸åº”ä¸ºç©º"
    print(f"   âœ“ Keyword Designer Role: {role}")
    print(f"   âœ“ Keyword Designer Goal: {goal[:50]}...")
    
    # æµ‹è¯• 3: è·å–é˜¶æ®µå·¥å…·
    print("\n3. æµ‹è¯•è·å–é˜¶æ®µå·¥å…·...")
    discovery_tools = get_available_tools("discovery")
    collection_tools = get_available_tools("collection")
    print(f"   âœ“ Discovery é˜¶æ®µå·¥å…·: {discovery_tools}")
    print(f"   âœ“ Collection é˜¶æ®µå·¥å…·: {collection_tools}")
    assert "web_search" in discovery_tools, "Discovery é˜¶æ®µåº”åŒ…å« web_search"
    assert "youtube_search" in collection_tools, "Collection é˜¶æ®µåº”åŒ…å« youtube_search"
    
    # æµ‹è¯• 4: è·å–å‹ç¼©æ¨¡æ¿
    print("\n4. æµ‹è¯•è·å–å‹ç¼©æ¨¡æ¿...")
    template = get_compression_template("candidates_summary_template")
    print(f"   âœ“ å‹ç¼©æ¨¡æ¿å­˜åœ¨: {bool(template)}")
    
    # æµ‹è¯• 5: åŠ¨æ€å˜é‡æ›¿æ¢
    print("\n5. æµ‹è¯•åŠ¨æ€å˜é‡æ›¿æ¢...")
    prompt_with_vars = get_prompt("keyword_designer", "system", topic="AIè§†é¢‘")
    assert "2025" in prompt_with_vars, "åº”åŒ…å«å½“å‰å¹´ä»½"
    print(f"   âœ“ å˜é‡æ›¿æ¢æˆåŠŸï¼ŒåŒ…å«å¹´ä»½: 2025")
    
    print("\nâœ… P0: PromptManager æµ‹è¯•é€šè¿‡!")
    return True


def test_tool_masker():
    """æµ‹è¯• P2: ToolMasker"""
    print("\n" + "="*60)
    print("æµ‹è¯• P2: ToolMasker")
    print("="*60)
    
    from core.tool_masker import (
        get_masked_tools,
        get_tool_descriptions,
        get_tool_hints,
        should_allow_tool,
        get_tool_masker
    )
    from core.state import RadarState
    
    # åˆ›å»ºæµ‹è¯•çŠ¶æ€
    state = RadarState(
        target_domains=["AI"],
        current_phase="collection"
    )
    
    # æµ‹è¯• 1: è·å–é˜¶æ®µå·¥å…·
    print("\n1. æµ‹è¯•è·å–é˜¶æ®µå·¥å…·...")
    tools = get_masked_tools(state)
    print(f"   âœ“ Collection é˜¶æ®µå¯ç”¨å·¥å…·: {tools}")
    assert "youtube_search" in tools, "Collection é˜¶æ®µåº”åŒ…å« youtube_search"
    assert "bilibili_search" in tools, "Collection é˜¶æ®µåº”åŒ…å« bilibili_search"
    
    # æµ‹è¯• 2: Monitor å·¥å…·éœ€è¦åšä¸»
    print("\n2. æµ‹è¯• Monitor å·¥å…·å‰ç½®æ¡ä»¶...")
    # æ— åšä¸»æ—¶
    tools_no_influencers = get_masked_tools(state)
    has_monitor = "youtube_monitor" in tools_no_influencers
    print(f"   âœ“ æ— åšä¸»æ—¶ youtube_monitor å¯ç”¨: {has_monitor}")
    
    # æœ‰åšä¸»æ—¶
    state.discovered_influencers = [{"name": "Test", "platform": "youtube"}]
    tools_with_influencers = get_masked_tools(state)
    has_monitor_now = "youtube_monitor" in tools_with_influencers
    print(f"   âœ“ æœ‰åšä¸»æ—¶ youtube_monitor å¯ç”¨: {has_monitor_now}")
    
    # æµ‹è¯• 3: è·å–å·¥å…·æè¿°
    print("\n3. æµ‹è¯•è·å–å·¥å…·æè¿°...")
    descriptions = get_tool_descriptions(state, format="brief")
    print(f"   âœ“ å·¥å…·æè¿° (brief): {descriptions}")
    
    descriptions_md = get_tool_descriptions(state, format="markdown")
    assert "youtube_search" in descriptions_md, "Markdown æè¿°åº”åŒ…å«å·¥å…·å"
    print(f"   âœ“ Markdown æè¿°é•¿åº¦: {len(descriptions_md)} å­—ç¬¦")
    
    # æµ‹è¯• 4: è·å–å·¥å…·æç¤º
    print("\n4. æµ‹è¯•è·å–å·¥å…·æç¤º...")
    hints = get_tool_hints(state)
    print(f"   âœ“ å·¥å…·æç¤º: {hints if hints else '(æ— )'}")
    
    # æµ‹è¯• 5: æ£€æŸ¥å·¥å…·æ˜¯å¦å…è®¸
    print("\n5. æµ‹è¯•æ£€æŸ¥å·¥å…·æ˜¯å¦å…è®¸...")
    allowed, reason = should_allow_tool("youtube_search", state)
    print(f"   âœ“ youtube_search å…è®¸: {allowed}, åŸå› : {reason}")
    
    # åˆ‡æ¢åˆ° init é˜¶æ®µ
    state.current_phase = "init"
    allowed_init, reason_init = should_allow_tool("youtube_search", state)
    print(f"   âœ“ init é˜¶æ®µ youtube_search å…è®¸: {allowed_init}, åŸå› : {reason_init}")
    
    print("\nâœ… P2: ToolMasker æµ‹è¯•é€šè¿‡!")
    return True


def test_context_compressor():
    """æµ‹è¯• P1: ContextCompressor"""
    print("\n" + "="*60)
    print("æµ‹è¯• P1: ContextCompressor")
    print("="*60)
    
    from core.context_compressor import (
        compress_candidates,
        compress_influencers,
        compress_tasks,
        compress_errors,
        compress_state,
        should_compress,
        estimate_tokens
    )
    from core.state import RadarState, ContentItem, TaskItem
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    candidates = []
    for i in range(30):
        platform = "youtube" if i % 2 == 0 else "bilibili"
        candidates.append(ContentItem(
            platform=platform,
            source_type="keyword_search",
            title=f"æµ‹è¯•è§†é¢‘ {i} - {'YouTube' if platform == 'youtube' else 'Bç«™'}",
            url=f"https://example.com/video/{i}",
            author_name=f"ä½œè€…{i}",
            author_id=str(i),
            publish_time="2025-11-28",  # æ·»åŠ å¿…éœ€å­—æ®µ
            view_count=10000 * (i + 1),
            interaction=1000 * (i + 1)
        ))
    
    # æµ‹è¯• 1: å‹ç¼©å€™é€‰å†…å®¹
    print("\n1. æµ‹è¯•å‹ç¼©å€™é€‰å†…å®¹...")
    summary = compress_candidates(candidates)
    print(f"   âœ“ å‹ç¼©ç»“æœ:\n{summary}")
    assert "30" in summary, "åº”æ˜¾ç¤ºæ€»æ•° 30"
    assert "YouTube" in summary, "åº”åŒ…å« YouTube"
    assert "Bilibili" in summary, "åº”åŒ…å« Bilibili"
    
    # æµ‹è¯• 2: å‹ç¼©åšä¸»åˆ—è¡¨
    print("\n2. æµ‹è¯•å‹ç¼©åšä¸»åˆ—è¡¨...")
    influencers = [
        {"name": "å½±è§†é£“é£", "platform": "bilibili"},
        {"name": "Two Minute Papers", "platform": "youtube"},
        {"name": "è€ç•ªèŒ„", "platform": "bilibili"},
    ]
    inf_summary = compress_influencers(influencers)
    print(f"   âœ“ åšä¸»æ‘˜è¦:\n{inf_summary}")
    
    # æµ‹è¯• 3: å‹ç¼©ä»»åŠ¡é˜Ÿåˆ—
    print("\n3. æµ‹è¯•å‹ç¼©ä»»åŠ¡é˜Ÿåˆ—...")
    tasks = [
        TaskItem(task_id="1", task_type="search", priority=10, engine="engine1", 
                 platform="youtube", tool_name="youtube_search", status="pending"),
        TaskItem(task_id="2", task_type="search", priority=9, engine="engine2", 
                 platform="bilibili", tool_name="bilibili_search", status="completed"),
    ]
    task_summary = compress_tasks(tasks)
    print(f"   âœ“ ä»»åŠ¡æ‘˜è¦:\n{task_summary}")
    
    # æµ‹è¯• 4: å‹ç¼©é”™è¯¯å†å²
    print("\n4. æµ‹è¯•å‹ç¼©é”™è¯¯å†å²...")
    errors = [
        {"tool_name": "youtube_search", "error_type": "timeout", "error": "è¯·æ±‚è¶…æ—¶"},
        {"tool_name": "youtube_search", "error_type": "timeout", "error": "è¯·æ±‚è¶…æ—¶"},
        {"tool_name": "bilibili_search", "error_type": "no_results", "error": "æ— ç»“æœ"},
    ]
    error_summary = compress_errors(errors)
    print(f"   âœ“ é”™è¯¯æ‘˜è¦:\n{error_summary}")
    assert "Ã— 2" in error_summary, "åº”èšåˆç›¸åŒé”™è¯¯"
    
    # æµ‹è¯• 5: å‹ç¼©æ•´ä¸ªçŠ¶æ€
    print("\n5. æµ‹è¯•å‹ç¼©æ•´ä¸ªçŠ¶æ€...")
    state = RadarState(
        target_domains=["AI"],
        current_phase="collection",
        candidates=candidates,
        discovered_influencers=influencers,
        task_queue=tasks,
        error_history=errors
    )
    full_summary = compress_state(state)
    print(f"   âœ“ å®Œæ•´çŠ¶æ€æ‘˜è¦:\n{full_summary}")
    
    # æµ‹è¯• 6: åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©
    print("\n6. æµ‹è¯•åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©...")
    needs_compress = should_compress(state)
    print(f"   âœ“ éœ€è¦å‹ç¼©: {needs_compress}")
    
    # æµ‹è¯• 7: Token ä¼°ç®—
    print("\n7. æµ‹è¯• Token ä¼°ç®—...")
    tokens = estimate_tokens(full_summary)
    print(f"   âœ“ ä¼°ç®— Token æ•°: {tokens}")
    
    print("\nâœ… P1: ContextCompressor æµ‹è¯•é€šè¿‡!")
    return True


def test_feedback_analyzer():
    """æµ‹è¯• P4: FeedbackAnalyzer"""
    print("\n" + "="*60)
    print("æµ‹è¯• P4: FeedbackAnalyzer")
    print("="*60)
    
    from core.feedback_analyzer import (
        analyze_result,
        get_retry_suggestion,
        get_success_params,
        get_failure_summary,
        get_analyzer
    )
    
    # æ¨¡æ‹Ÿç»“æœå¯¹è±¡
    class MockResult:
        def __init__(self, status, data=None, error=None):
            self.status = status
            self.data = data or []
            self.error = error
    
    # æµ‹è¯• 1: åˆ†ææˆåŠŸç»“æœ
    print("\n1. æµ‹è¯•åˆ†ææˆåŠŸç»“æœ...")
    success_result = MockResult("success", data=[{"title": "è§†é¢‘1"}, {"title": "è§†é¢‘2"}])
    analysis = analyze_result(
        tool_name="youtube_search",
        params={"keyword": "AI tutorial", "limit": 10},
        result=success_result
    )
    print(f"   âœ“ æˆåŠŸåˆ†æ: success={analysis['success']}, count={analysis['result_count']}")
    assert analysis['success'] == True
    assert analysis['result_count'] == 2
    
    # æµ‹è¯• 2: åˆ†æå¤±è´¥ç»“æœ
    print("\n2. æµ‹è¯•åˆ†æå¤±è´¥ç»“æœ...")
    error_result = MockResult("error", error="Connection timeout")
    error_analysis = analyze_result(
        tool_name="bilibili_search",
        params={"keyword": "AIæ•™ç¨‹", "limit": 15},
        result=error_result
    )
    print(f"   âœ“ å¤±è´¥åˆ†æ: success={error_analysis['success']}, error_type={error_analysis.get('error_type', 'N/A')}")
    assert error_analysis['success'] == False
    
    # æµ‹è¯• 3: è·å–é‡è¯•å»ºè®®
    print("\n3. æµ‹è¯•è·å–é‡è¯•å»ºè®®...")
    suggestion = get_retry_suggestion(
        tool_name="youtube_search",
        error="timeout error occurred",
        original_params={"keyword": "AI", "limit": 20}
    )
    print(f"   âœ“ é‡è¯•å»ºè®®: should_retry={suggestion['should_retry']}, reason={suggestion['reason']}")
    if suggestion.get('adjusted_params'):
        print(f"   âœ“ è°ƒæ•´åå‚æ•°: {suggestion['adjusted_params']}")
    
    # æµ‹è¯• 4: æµ‹è¯•æ— ç»“æœåœºæ™¯
    print("\n4. æµ‹è¯•æ— ç»“æœåœºæ™¯...")
    no_result = MockResult("success", data=[])
    no_result_analysis = analyze_result(
        tool_name="bilibili_search",
        params={"keyword": "éå¸¸å†·é—¨çš„å…³é”®è¯", "limit": 10},
        result=no_result
    )
    print(f"   âœ“ æ— ç»“æœåˆ†æ: issues={no_result_analysis['issues']}")
    print(f"   âœ“ å»ºè®®: {no_result_analysis['suggestions']}")
    
    # æµ‹è¯• 5: è·å–å¤±è´¥æ‘˜è¦
    print("\n5. æµ‹è¯•è·å–å¤±è´¥æ‘˜è¦...")
    summary = get_failure_summary()
    print(f"   âœ“ å¤±è´¥æ‘˜è¦:\n{summary}")
    
    # æµ‹è¯• 6: è·å–æˆåŠŸå‚æ•°
    print("\n6. æµ‹è¯•è·å–æˆåŠŸå‚æ•°...")
    success_params = get_success_params("youtube_search")
    print(f"   âœ“ æˆåŠŸå‚æ•°: {success_params}")
    
    print("\nâœ… P4: FeedbackAnalyzer æµ‹è¯•é€šè¿‡!")
    return True


def test_integration():
    """é›†æˆæµ‹è¯• - éªŒè¯æ‰€æœ‰æ¨¡å—ååŒå·¥ä½œ"""
    print("\n" + "="*60)
    print("é›†æˆæµ‹è¯• - éªŒè¯æ¨¡å—ååŒ")
    print("="*60)
    
    from core.state import RadarState, ContentItem
    from core.prompt_manager import build_state_summary, build_error_summary, build_goal_recap
    from core.tool_masker import get_masked_tools, get_tool_hints
    from core.context_compressor import compress_state, should_compress
    
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„è¿è¡ŒçŠ¶æ€
    state = RadarState(
        target_domains=["AIè§†é¢‘"],
        current_phase="collection",
        session_focus={"priority_topics": ["AIè§†é¢‘ç”Ÿæˆ"]},  # ä¿®å¤ä¸ºå­—å…¸æ ¼å¼
        candidates=[
            ContentItem(
                platform="youtube",
                source_type="keyword_search",
                title="AI Video Generation Tutorial",
                url="https://youtube.com/watch?v=123",
                author_name="TechChannel",
                author_id="UC123",
                publish_time="2025-11-28",  # æ·»åŠ å¿…éœ€å­—æ®µ
                view_count=50000,
                interaction=5000
            ),
            ContentItem(
                platform="bilibili",
                source_type="keyword_search",
                title="AIè§†é¢‘ç”Ÿæˆæ•™ç¨‹",
                url="https://bilibili.com/video/BV123",
                author_name="æŠ€æœ¯UPä¸»",
                author_id="12345",
                publish_time="2025-11-28",  # æ·»åŠ å¿…éœ€å­—æ®µ
                view_count=30000,
                interaction=3000
            )
        ],
        discovered_influencers=[
            {"name": "Two Minute Papers", "platform": "youtube", "identifier": "@TwoMinutePapers"}
        ],
        error_history=[
            {"tool_name": "youtube_search", "error": "timeout", "error_type": "timeout"}
        ]
    )
    
    print("\n1. æµ‹è¯•çŠ¶æ€æ‘˜è¦æ„å»º...")
    state_summary = build_state_summary(state)
    print(f"   âœ“ çŠ¶æ€æ‘˜è¦:\n{state_summary}")
    
    print("\n2. æµ‹è¯•é”™è¯¯æ‘˜è¦æ„å»º...")
    error_summary = build_error_summary(state)
    print(f"   âœ“ é”™è¯¯æ‘˜è¦:\n{error_summary if error_summary else '(æ— )'}")
    
    print("\n3. æµ‹è¯•ç›®æ ‡æé†’æ„å»º...")
    goal_recap = build_goal_recap(state, target_items=50)
    print(f"   âœ“ ç›®æ ‡æé†’:\n{goal_recap}")
    
    print("\n4. æµ‹è¯•å·¥å…·å±è”½...")
    available_tools = get_masked_tools(state)
    print(f"   âœ“ å¯ç”¨å·¥å…·: {available_tools}")
    
    print("\n5. æµ‹è¯•å·¥å…·æç¤º...")
    hints = get_tool_hints(state)
    print(f"   âœ“ å·¥å…·æç¤º: {hints if hints else '(æ— )'}")
    
    print("\n6. æµ‹è¯•å‹ç¼©åˆ¤æ–­...")
    needs_compress = should_compress(state)
    print(f"   âœ“ éœ€è¦å‹ç¼©: {needs_compress}")
    
    if needs_compress:
        compressed = compress_state(state)
        print(f"   âœ“ å‹ç¼©åæ‘˜è¦:\n{compressed}")
    
    print("\nâœ… é›†æˆæµ‹è¯•é€šè¿‡!")
    return True


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("="*60)
    print("å¼€å§‹æµ‹è¯•æ–°æ”¹è¿›æ¨¡å—")
    print("="*60)
    
    all_passed = True
    
    try:
        all_passed &= test_prompt_manager()
    except Exception as e:
        print(f"\nâŒ P0 æµ‹è¯•å¤±è´¥: {e}")
        all_passed = False
    
    try:
        all_passed &= test_tool_masker()
    except Exception as e:
        print(f"\nâŒ P2 æµ‹è¯•å¤±è´¥: {e}")
        all_passed = False
    
    try:
        all_passed &= test_context_compressor()
    except Exception as e:
        print(f"\nâŒ P1 æµ‹è¯•å¤±è´¥: {e}")
        all_passed = False
    
    try:
        all_passed &= test_feedback_analyzer()
    except Exception as e:
        print(f"\nâŒ P4 æµ‹è¯•å¤±è´¥: {e}")
        all_passed = False
    
    try:
        all_passed &= test_integration()
    except Exception as e:
        print(f"\nâŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        all_passed = False
    
    print("\n" + "="*60)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹é”™è¯¯ä¿¡æ¯")
    print("="*60)
    
    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

