# Analyst 意图驱动重构 - 实施报告

**日期**: 2025-11-28
**状态**: ✅ 实施完成
**目标**: 从"分类驱动"转向"意图驱动"，提升分析质量和搜索精准度

---

## 📋 核心问题回顾

### 原有设计的4大问题

1. **语言不匹配** ❌
   - 现象: 系统输出英文，用户需要中文
   - 影响: 用户体验差，日志难读

2. **搜索策略错配** ❌
   - 现象: B站实用教程选题 → 分类为"social_cognition" → 搜索PubMed学术论文
   - 结果: 67%搜索结果不相关（4/12个来源有用）
   - 示例: "学习方法"选题搜到 Feynman 物理学讲义

3. **分类系统僵化** ❌
   - 问题: 硬编码分类（tech_ai/business/social）→ 查表式搜索策略
   - 本质: "削足适履"，强行把多样化选题塞进固定分类
   - 后果: 无法适应实际需求，误分类导致搜索失败

4. **已有素材浪费** ❌
   - 问题: `reference_data` 包含11.9w+播放量高质量视频，但完全被忽略
   - 影响: 重复搜索外部资源，成本浪费，错失现成素材

---

## 🎯 解决方案总览

### 核心思路: 意图驱动

```
【旧模式】分类驱动 (Classification-Driven)
选题 → 分类(tech/business/social) → 查表(lookup_table) → 执行预定义策略

【新模式】意图驱动 (Intent-Driven)
选题 + 已有素材 + 上下文 → LLM推理(需要什么信息?) → 动态设计策略 → 执行
```

### 设计原则

1. **不问LLM**: "这个选题属于哪个类别？"
2. **而问LLM**: "为了深入研究这个选题，你需要去哪找资料？"

---

## 🔧 具体实施

### 1. 修复输出语言 (P0) ✅

**修改文件**: `nodes/analyst.py`

**变更内容**:

#### 1.1 Scout 系统提示词 (lines 104-109)
```python
# 修改前
system_prompt="You are an expert research strategist..."

# 修改后
system_prompt="""你是一位专业的研究策略专家。你的任务是为深度分析找到最佳的一手资料来源。

核心原则：
- 所有输出必须使用中文
- 优先寻找一手资料而非二手信息
- 搜索策略要具体、可执行"""
```

#### 1.2 Excavator 系统提示词 (lines 297-303)
```python
system_prompt="""你是一位专业的信息提取专家。你的任务是从长文本中提取可验证的事实和原文引用。

核心原则：
- 所有输出必须使用中文
- 只提取可验证的事实，拒绝编造
- 保留原文引用（quote字段），确保准确性
- 如果内容不相关，返回空列表"""
```

#### 1.3 Philosopher 系统提示词 (lines 457-467)
```python
system_prompt="""你是一位世界级的深度分析专家，融合了：
- 科学家的严谨性（验证一切）
- 哲学家的洞察力（发现深层真理）
- 故事讲述者的表达力（清晰传达）

核心原则：
1. 所有输出必须使用中文
2. 每个结论必须有证据支撑
3. 追求反直觉的洞察（而非显而易见的观点）
4. 使用思维模型解释"为什么"
5. 让分析结果可用于内容创作"""
```

**影响**: 所有输出（日志、分析报告）现在都使用中文

---

### 2. 传递 reference_data (P0) ✅

**新增函数**: `_summarize_reference_data()` (lines 24-55)

**功能**: 将 TopicBrief.reference_data 转换为简洁摘要

```python
def _summarize_reference_data(reference_data: List[Dict[str, Any]]) -> str:
    """
    将 reference_data 转换为简洁的摘要文本，供 LLM 参考
    """
    if not reference_data:
        return "无已有素材"

    summary_lines = []
    for idx, ref in enumerate(reference_data[:10], 1):  # 最多展示 10 条
        platform = ref.get('platform', '未知平台')
        title = ref.get('title', '无标题')
        view_count = ref.get('view_count', 0)
        author = ref.get('author_name', '未知作者')

        # 提取描述信息（如果有）
        desc = ""
        if 'raw_data' in ref and isinstance(ref['raw_data'], dict):
            desc = ref['raw_data'].get('description', '') or ref['raw_data'].get('summary', '')
            if desc:
                desc = desc[:150] + "..." if len(desc) > 150 else desc

        summary_lines.append(
            f"{idx}. [{platform}] {title}\n"
            f"   播放: {view_count:,} | 作者: {author}"
            + (f"\n   简介: {desc}" if desc else "")
        )

    if len(reference_data) > 10:
        summary_lines.append(f"\n... 以及其他 {len(reference_data) - 10} 条素材")

    return "\n\n".join(summary_lines)
```

**调用点**: `plan_research_strategy()` (lines 67-72)

```python
# 🔑 提取 reference_data 信息
ref_count = len(topic_brief.reference_data)
ref_summary = _summarize_reference_data(topic_brief.reference_data)

# 🔑 提取平台信息
platforms = set()
for ref in topic_brief.reference_data:
    if isinstance(ref, dict) and 'platform' in ref:
        platforms.add(ref['platform'])
platform_str = ', '.join(platforms) if platforms else '未知'
```

**影响**: Scout 现在能看到已收集的素材信息

---

### 3. 重写 Scout Prompt 为意图驱动 (P1) ✅

**核心变更**: `plan_research_strategy()` 的 user_prompt (lines 75-185)

#### 3.1 新提示词结构

```markdown
# 你的任务：理解选题意图，设计最优搜索策略

## 背景信息
- 选题标题、切入点、理由、来源类型
- 已有素材 (N 条，来自 X平台)
  [详细列表]

## 你的推理过程（请逐步思考）

### Step 1: 理解选题的真实意图
- 这个选题想解决什么问题？
- 目标受众是谁？
- 需要什么层次的信息？

### Step 2: 分析已有素材
- 这些视频提供了什么角度？
- 还缺少什么信息？
- 是否需要外部补充？

### Step 3: 设计搜索策略
[根据选题类型动态设计]

#### 3.3.1 实用技巧类选题
- 优先: 知乎专栏、小红书实战、B站教程评论区
- 次选: Reddit讨论、实践者博客
- 避免: 学术论文（太理论）

#### 3.3.2 技术原理类选题
- 优先: Arxiv论文、官方技术文档、GitHub实现
- 次选: 高质量技术博客
- 避免: 营销软文

#### 3.3.3 观点争议类选题
- 优先: 反方观点来源、数据验证
- 次选: 主流观点综述
- 避免: 单一立场来源
```

#### 3.2 关键改进点

1. **去除硬编码分类**
   - 删除: tech_ai/business_finance/social_cognition 分类
   - 替换: 动态推理选题类型

2. **提供已有素材上下文**
   - 包含: 平台、标题、播放量、作者、描述
   - 让 Scout 判断是否需要外部搜索

3. **引导逐步推理**
   - Step 1: 理解意图
   - Step 2: 分析现有素材
   - Step 3: 设计策略

4. **提供实战示例**
   - 关键词设计: 保留中文黑话 vs 翻译通用概念
   - 好例子: "知乎 2+3+5 学习法" (保留黑话)
   - 坏例子: "2-3-5 time blocking study" (生硬翻译)

---

### 4. 实现 analyze_existing 工具 (P1) ✅

**目标**: 允许 Scout 直接分析已有素材，无需外部搜索

#### 4.1 修改 ContentProcessor 初始化 (line 237-240)

```python
# 修改前
def __init__(self):
    self.search_gateway = SearchGateway()
    self.arxiv_searcher = ArxivSearcher()

# 修改后
def __init__(self, reference_data: List[Dict[str, Any]] = None):
    self.search_gateway = SearchGateway()
    self.arxiv_searcher = ArxivSearcher()
    self.reference_data = reference_data or []  # 🔑 存储已有素材
```

#### 4.2 添加新工具类型 (lines 265-269)

```python
try:
    if tool == "analyze_existing":
        # 🔑 新工具: 直接分析已有素材
        results = self._analyze_existing_materials(query, target)
        all_results.extend(results)

    elif tool == "arxiv_search":
        ...
```

#### 4.3 实现分析逻辑 (lines 311-368)

```python
def _analyze_existing_materials(self, query: str, target: str) -> List[Dict[str, Any]]:
    """
    🔑 新功能: 分析已有素材（reference_data）

    参数:
        query: 分析关键词（用于筛选相关素材，"*" 表示分析所有）
        target: 期望提取的信息类型

    返回:
        标准化的搜索结果格式，供 extract_insights 使用
    """
    if not self.reference_data:
        print(f"   ⚠️ 无已有素材可分析")
        return []

    results = []
    query_lower = query.lower()

    for ref in self.reference_data[:10]:  # 最多分析10条
        # 提取基础信息
        title = ref.get('title', '')
        platform = ref.get('platform', '未知平台')
        author = ref.get('author_name', '未知作者')
        url = ref.get('url', '')
        view_count = ref.get('view_count', 0)

        # 提取描述/摘要作为内容
        raw_data = ref.get('raw_data', {})
        content = raw_data.get('description', '') or raw_data.get('summary', '')

        # 简单的相关性筛选
        is_relevant = (
            query_lower in title.lower() or
            query_lower in content.lower() or
            query == "*"  # "*" 表示分析所有素材
        )

        if is_relevant and content:
            results.append({
                "source": f"[{platform}] {title} - {author}",
                "url": url,
                "content": f"""
**平台**: {platform}
**标题**: {title}
**作者**: {author}
**播放量**: {view_count:,}
**链接**: {url}

**内容描述**:
{content}
""",
                "is_primary": True,  # 已收集的视频是一手素材
                "search_target": target
            })
            print(f"   ✅ 匹配到素材: {title[:40]}...")

    print(f"   📦 从已有素材中提取了 {len(results)} 条相关内容")
    return results
```

#### 4.4 连接到主流程 (line 674)

```python
# 修改前
processor = ContentProcessor()

# 修改后
processor = ContentProcessor(reference_data=topic_brief.reference_data)  # 🔑 传递已有素材
```

**工具使用示例**:

```json
{
  "tool": "analyze_existing",
  "query": "*",
  "target": "用户对学习方法的真实反馈和实战经验",
  "priority": 1
}
```

**影响**:
- Scout 可以选择直接分析已有视频描述
- 避免重复搜索
- 充分利用已收集的高质量素材

---

## 📊 改进效果预测

### Before vs After

| 维度 | 改进前 | 改进后 | 提升 |
|------|--------|--------|------|
| **输出语言** | 英文 | 中文 | 用户体验 ↑ |
| **搜索精准度** | 67%不相关 | 预计 85%+ 相关 | 质量 ↑ |
| **素材利用** | 0% (忽略) | 优先使用 | 成本 ↓ |
| **策略灵活性** | 4种固定分类 | 动态推理 | 适配性 ↑ |

### 成本优化

**场景**: B站实用教程选题 + 已有5条高质量视频

**改进前**:
1. 忽略已有素材
2. 搜索 PubMed → 无关结果 → $0.01
3. 搜索 Arxiv → 无关结果 → $0.005
4. 搜索 Web (通用) → 低质量结果 → $0.015
5. **总成本**: ~$0.03, **有效率**: 33%

**改进后**:
1. 分析已有5条视频 → 直接提取洞察 → $0.002
2. 补充搜索知乎实战案例 → 高相关 → $0.01
3. **总成本**: ~$0.012, **有效率**: 90%+

**节省**: 60%成本, 质量提升2.7倍

---

## 🧪 测试建议

### 测试用例 1: B站实用教程选题

**输入**:
```python
TopicBrief(
    title="2+3+5学习法实战",
    core_angle="知乎高赞方法在实际学习中的效果验证",
    source_type="search",
    reference_data=[
        {
            "platform": "bilibili",
            "title": "我用2+3+5学习法考上清华",
            "view_count": 119000,
            "author_name": "学霸UP主",
            "raw_data": {
                "description": "详细记录了3个月使用该方法的心得..."
            }
        },
        # ... 更多素材
    ]
)
```

**预期输出** (Scout):
```json
{
  "topic_category": "practical_tutorial",
  "search_strategy": "优先分析已有B站实战案例，补充知乎原创讨论",
  "search_instructions": [
    {
      "tool": "analyze_existing",
      "query": "*",
      "target": "实战经验、效果反馈、踩坑记录",
      "priority": 1
    },
    {
      "tool": "web_search",
      "query": "知乎 2+3+5学习法 真实评价",
      "target": "用户反馈和争议点",
      "priority": 2
    }
  ],
  "reasoning": "已有素材包含实战案例，优先分析。补充知乎讨论找争议点。"
}
```

### 测试用例 2: AI技术原理选题

**输入**:
```python
TopicBrief(
    title="Transformer注意力机制深度解析",
    core_angle="从数学原理到代码实现",
    source_type="tech_news",
    reference_data=[]  # 无已有素材
)
```

**预期输出** (Scout):
```json
{
  "topic_category": "technical_deep_dive",
  "search_strategy": "学术论文奠定理论基础，GitHub找实现细节",
  "search_instructions": [
    {
      "tool": "arxiv_search",
      "query": "Attention Is All You Need Transformer",
      "target": "原始论文和数学推导",
      "priority": 1
    },
    {
      "tool": "web_search",
      "query": "Transformer attention implementation annotated code",
      "target": "带注释的实现代码",
      "priority": 2
    }
  ],
  "reasoning": "技术原理需要学术论文支撑，代码实现补充实践理解。"
}
```

### 验证清单

- [ ] Scout 输出全部为中文
- [ ] Excavator 输出全部为中文
- [ ] Philosopher 输出全部为中文
- [ ] Scout 能正确识别实用类选题（不再错分为 social_cognition）
- [ ] analyze_existing 工具正常工作
- [ ] 当 reference_data 为空时，降级为外部搜索
- [ ] 当 reference_data 充足时，优先使用已有素材
- [ ] 搜索结果相关性 > 80%

---

## 📂 文件变更清单

### 修改文件

**1. `nodes/analyst.py`** (主要改动)

| 行号 | 变更类型 | 说明 |
|------|----------|------|
| 24-55 | 新增函数 | `_summarize_reference_data()` |
| 58-185 | 重写 | `plan_research_strategy()` - 意图驱动 Prompt |
| 104-109 | 修改 | Scout 系统提示词 → 中文 |
| 237-240 | 修改 | ContentProcessor `__init__` 接收 reference_data |
| 265-269 | 新增 | 支持 `analyze_existing` 工具 |
| 311-368 | 新增方法 | `_analyze_existing_materials()` |
| 297-303 | 修改 | Excavator 系统提示词 → 中文 |
| 457-467 | 修改 | Philosopher 系统提示词 → 中文 |
| 674 | 修改 | 传递 reference_data 给 ContentProcessor |

### 新增文件

**1. `调研报告-意图驱动重构.md`**
- 深度调研文档
- 分析现有问题
- 提出解决方案

**2. `意图驱动重构-实施报告.md`** (本文档)
- 实施细节
- 代码变更
- 测试建议

---

## 🎓 设计哲学

### 核心洞察

> **分类（Classification）不仅可能是错误的，它在智能体设计中往往就是'削足适履'的元凶。**

**为什么分类驱动会失败？**

1. **固定分类无法覆盖多样性**
   - 现实中选题千变万化
   - 强行塞进4个分类 → 必然错配

2. **查表式策略缺乏灵活性**
   - 分类 → 查表 → 执行
   - 无法根据具体上下文调整

3. **忽略了 LLM 的推理能力**
   - LLM 擅长推理，不需要人为分类
   - 直接问"需要什么信息"比问"属于哪个类别"更有效

### 意图驱动的优势

1. **上下文感知**
   - 考虑选题本身
   - 考虑已有素材
   - 考虑目标受众

2. **动态策略生成**
   - 每个选题定制化搜索
   - 根据信息缺口调整

3. **充分利用资源**
   - 优先使用已有素材
   - 避免重复搜索
   - 成本最优

---

## 🚀 后续优化方向

### Phase 2: 搜索质量提升

- [ ] 实现 `github_search` 工具（代码仓库分析）
- [ ] 实现 `reddit_search` 工具（社区讨论）
- [ ] 增强关键词生成逻辑（NER + 实体识别）

### Phase 3: 素材分析增强

- [ ] 视频字幕提取（YouTube/B站）
- [ ] 评论区情感分析
- [ ] 数据趋势分析（播放量、点赞率）

### Phase 4: 智能去重

- [ ] 检测已分析过的选题
- [ ] 避免重复搜索相同关键词
- [ ] 缓存常用搜索结果

---

## ✅ 验收标准

### 功能完整性
- [x] 所有输出使用中文
- [x] reference_data 成功传递
- [x] 意图驱动 Prompt 实现
- [x] analyze_existing 工具实现
- [ ] 集成测试通过
- [ ] 真实选题验证

### 代码质量
- [x] 无语法错误
- [x] 类型注解完整
- [x] 文档注释充分
- [ ] 单元测试覆盖

### 性能指标
- [ ] 搜索相关性 > 80%
- [ ] 成本降低 > 40%
- [ ] 分析质量评分 > 4.0/5.0

---

## 📝 总结

### 核心成果

1. **语言统一**: 全中文输出，用户体验提升
2. **策略优化**: 从固定分类 → 动态推理，精准度提升
3. **资源利用**: 优先使用已有素材，成本降低
4. **系统灵活**: 适配多样化选题，不再"削足适履"

### 设计原则

- **意图优先**: 理解需求，而非强行分类
- **上下文感知**: 考虑已有信息，避免盲目搜索
- **成本最优**: 优先使用现成资源
- **质量导向**: 一手资料 > 二手信息

### 下一步

1. **运行集成测试**: `python main.py`
2. **验证输出语言**: 检查所有日志是否为中文
3. **测试搜索策略**: 使用真实选题验证精准度
4. **分析成本收益**: 对比改进前后的搜索效率

---

**实施完成时间**: 2025-11-28
**实施者**: Claude Code
**验证者**: 待测试

🎉 **意图驱动重构完成！**
