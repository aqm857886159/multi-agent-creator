# 内容雷达系统优化总结

## 🎯 优化目标
解决测试中发现的三大核心问题：
1. **Bilibili 搜索完全失败** (0条数据)
2. **YouTube 搜索相关性差** (iPad视频混入AI视频生成搜索)
3. **时间筛选过于严格** (87-88%数据被过滤)

---

## ✅ 已完成的优化

### 1. **YouTube 爆款分相关性权重** (P0 - 高优先级)

**问题**: 搜索"AI生成视频"返回iPad、Windows视频，因为爆款分只考虑播放量、时效性、时长，不考虑相关性。

**解决方案**: 在爆款分公式中加入相关性权重

**修改文件**: `tools/youtube_scout.py`

**核心改动**:
```python
# 旧公式
viral_score = view_ratio * freshness * duration_weight

# 新公式
viral_score = view_ratio * freshness * duration_weight * relevance_weight
```

**相关性权重算法** (第221-263行):
```python
def _calculate_relevance(self, title: str, keyword: str) -> float:
    """
    计算标题与搜索词的相关性权重

    策略：
    1. 提取关键词中的核心术语（去除stop words）
    2. 计算标题中匹配的比例
    3. 低相关性大幅降权，高相关性加权

    Returns:
        0.2 - 2.0 之间的权重值
    """
    # 标准化处理
    title_lower = title.lower()
    keyword_lower = keyword.lower()

    # 移除常见的无意义词
    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'from', 'latest', '2025', '2024', '11', '10', '12'}

    # 提取关键词中的核心词
    keyword_terms = [term for term in keyword_lower.split() if term not in stop_words and len(term) > 2]

    # 计算匹配度
    matched_count = sum(1 for term in keyword_terms if term in title_lower)
    match_ratio = matched_count / len(keyword_terms)

    # 相关性权重映射
    if match_ratio >= 0.8:
        return 2.0  # 高度相关，翻倍
    elif match_ratio >= 0.5:
        return 1.5  # 中度相关，加权50%
    elif match_ratio >= 0.3:
        return 1.0  # 基本相关，保持
    elif match_ratio >= 0.1:
        return 0.5  # 低相关性，减半
    else:
        return 0.2  # 几乎不相关，大幅降权
```

**效果预期**:
- iPad、Windows 等不相关视频将被降权至 0.2-0.5×
- 高度相关的"AI视频生成"内容将获得 1.5-2.0× 加权
- 搜索结果相关性显著提升

---

### 2. **AI驱动的搜索词优化** (P0 - 用户明确要求)

**问题**: 搜索词生成使用硬编码模板（如 "best {topic} YouTube channels"），缺乏灵活性和智能性。

**解决方案**: 使用AI驱动的通用策略，根据主题特性动态生成搜索词

**修改文件**: `nodes/keyword_designer.py`

**核心改进**:

#### 2.1 **Discovery Query (发现博主) - AI驱动策略**
不再使用固定模板，而是根据主题类型智能选择：
- **技术类主题**: "top", "best", "channels to follow", "creators", "博主推荐"
- **新闻类主题**: "news sources", "trusted channels", "最佳新闻频道"
- **娱乐/生活类**: "popular", "trending", "must watch", "值得关注的UP主"
- **学术/教育类**: "educational", "learn from", "教程博主"

#### 2.2 **Content Query (搜索内容) - AI驱动策略**
根据主题特性选择最合适的搜索角度：
- **新闻类**: "latest news", "breaking", "update", "最新动态", "新闻速递"
- **技术类**: "tutorial", "explained", "guide", "deep dive", "教程", "解析"
- **趋势类**: "viral", "trending", "爆火", "热门"
- **评测类**: "review", "comparison", "测评", "对比"
- **事件类**: "highlights", "recap", "解读", "盘点"

#### 2.3 **搜索词质量标准**
- 必须自然、符合用户实际搜索习惯
- 避免过于生硬的模板化表达
- 考虑不同平台（YouTube, Bilibili）的用户搜索习惯差异
- 中文搜索词要符合中文用户的表达方式，不是英文的直译
- 对于陌生主题，智能推断其所属领域（科技/娱乐/新闻等），然后选择合适的搜索词风格

**效果预期**:
- 搜索词更符合用户实际搜索习惯
- 不同主题使用不同风格的搜索词
- 提升搜索结果的相关性和质量

---

### 3. **Bilibili API Credential 错误修复** (P0 - 关键bug)

**问题**: Bilibili 搜索失败，错误信息：`search_by_type() got an unexpected keyword argument 'credential'`

**根本原因**: `bilibili-api-python` 的 `search.search_by_type()` 函数不接受 `credential` 参数。搜索功能在游客模式下也能正常工作。

**解决方案**: 移除 `credential` 参数

**修改文件**: `tools/adapters/bilibili_adapter.py`

**核心改动** (第121-129行):
```python
# 修复前
results = sync(search.search_by_type(
    keyword=keyword,
    search_type=search.SearchObjectType.VIDEO,
    order_type=order_type,
    page=current_page,
    page_size=20,
    credential=self.credential  # ❌ 这里导致错误
))

# 修复后
results = sync(search.search_by_type(
    keyword=keyword,
    search_type=search.SearchObjectType.VIDEO,
    order_type=order_type,
    page=current_page,
    page_size=20
    # ✅ 移除 credential，游客模式正常工作
))
```

**注意**:
- `credential` 仍然用于其他需要认证的操作（如监控UP主、获取详细信息）
- 仅在 `search_by_type()` 中移除，其他地方保持不变

**效果预期**:
- Bilibili 搜索恢复正常
- 能够正常获取B站视频数据

---

## 🔄 关于时间筛选

**现状**: 87-88%的数据被时间筛选过滤掉

**分析**:
1. **不是筛选标准的问题** - 而是搜索策略的问题
2. YouTube 已经使用 `ytsearch` (relevance) 或 `ytsearchdate` (by time)
3. 已经在评分阶段有时间筛选 (line 176: `if days_old > days: continue`)

**当前策略**: 保持不变
- 时间筛选标准合理（30-60天）
- 真正的问题是搜索相关性（已通过相关性权重解决）
- 如果搜索词优化后，返回的视频本身就更新更相关，通过时间筛选的比例会自然提升

---

## 📊 优化影响预测

### **优化前问题汇总**:
```
输入: 54 条 (🔴41 🔵13)
   引擎1通过时效检查: 5/41 (12%)
   引擎2通过时效检查: 2/13 (15%)
   引擎2符合筛选标准: 2/2
输出: 7 条

问题:
1. Bilibili: 0 条数据
2. YouTube: iPad/Windows 视频混入
3. 时间筛选: 87-88% 被过滤
```

### **优化后预期**:
```
✅ Bilibili 恢复正常: 预计 15-20 条数据
✅ YouTube 相关性提升: iPad/Windows 视频被降权
✅ 搜索词智能化: 更符合用户搜索习惯
✅ 时间筛选通过率提升: 预计从 12-15% 提升到 30-40%
```

---

## 🧪 测试建议

### **测试命令**:
```bash
python main.py --topic "AI生成视频" --max-results 10
```

### **关键观察点**:
1. ✅ **Bilibili 是否有数据**: 应该能看到 15-20 条 Bilibili 视频
2. ✅ **YouTube 相关性**: 不应再出现 iPad/Windows 等无关视频
3. ✅ **搜索词质量**: 观察生成的搜索词是否自然、符合习惯
4. ✅ **时间筛选通过率**: 观察 "引擎X通过时效检查" 的比例是否提升
5. ✅ **最终输出质量**: Top 10 结果是否都高度相关

### **对比测试**:
| 指标 | 优化前 | 优化后 (预期) |
|------|--------|---------------|
| Bilibili 数据 | 0 条 | 15-20 条 |
| YouTube 相关性 | 混入 iPad 视频 | 高度相关 |
| 时间筛选通过率 | 12-15% | 30-40% |
| 最终输出 | 7 条 | 10 条 |

---

## 📝 技术总结

### **核心优化思路**:
1. **相关性优先**: 爆款分不仅看播放量，更要看相关性
2. **AI驱动**: 搜索词生成不用固定模板，而是根据主题智能调整
3. **API修复**: 正确理解第三方库的参数使用方式

### **代码改动统计**:
- `tools/youtube_scout.py`: +60 行 (新增相关性计算)
- `nodes/keyword_designer.py`: +30 行 (增强AI提示词)
- `tools/adapters/bilibili_adapter.py`: -1 行 (移除错误参数)

### **性能影响**:
- 相关性计算增加的开销: 忽略不计 (简单字符串匹配)
- AI搜索词生成: 无影响 (已经在使用LLM)
- Bilibili API修复: 性能提升 (从失败到成功)

---

## 🚀 下一步计划

1. **运行完整测试**: 使用 `python main.py --topic "AI生成视频"` 验证优化效果
2. **观察日志输出**: 确认 Bilibili 数据恢复、YouTube 相关性提升
3. **根据测试结果微调**: 如需要，调整相关性权重的阈值（当前 0.2-2.0）
4. **多主题测试**: 测试不同类型主题（新闻、技术、娱乐）的搜索词生成效果

---

## 🎉 预期成果

经过这三项核心优化后，系统应该能够：
1. ✅ 正常获取 Bilibili 视频数据（从 0 条到 15-20 条）
2. ✅ YouTube 搜索结果高度相关（不再混入无关视频）
3. ✅ 搜索词更自然、智能（AI驱动，非模板化）
4. ✅ 整体数据质量显著提升
5. ✅ 最终输出的 Top 10 内容更精准、更有价值

让我们运行测试验证效果！🚀
