from typing import Dict, Any, List
from pydantic import BaseModel, Field
from core.state import RadarState
from core.llm import get_llm_with_schema

class InfluencerInfo(BaseModel):
    """åšä¸»ä¿¡æ¯"""
    name: str = Field(..., description="åšä¸»åç§°")
    platform: str = Field(..., description="å¹³å°: youtube æˆ– bilibili")
    identifier: str = Field(..., description="åšä¸»æ ‡è¯†ï¼ˆ@handle, é¢‘é“URL, æˆ– UPä¸»IDï¼‰")
    mention_count: int = Field(default=1, description="åœ¨æ–‡ç« ä¸­å‡ºç°æ¬¡æ•°ï¼ˆæƒé‡ï¼‰")
    source_url: str = Field(default="", description="æ¥æºæ–‡ç« URL")
    confidence: str = Field(default="medium", description="ç½®ä¿¡åº¦: high/medium/low")

class InfluencerExtractorOutput(BaseModel):
    """æå–çš„åšä¸»åˆ—è¡¨"""
    influencers: List[InfluencerInfo] = Field(default_factory=list, description="å‘ç°çš„åšä¸»åˆ—è¡¨")
    summary: str = Field(..., description="æå–æ€»ç»“")
    total_sources_analyzed: int = Field(default=0, description="åˆ†æçš„æ–‡ç« æ•°é‡")

def run_influencer_extractor(state: RadarState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹: åšä¸»æå–å™¨ (Influencer Extractor)

    åŠŸèƒ½: ä» Web æœç´¢ç»“æœä¸­æå–é¡¶çº§åšä¸»ä¿¡æ¯
    - è¾“å…¥: state.leads (Web æœç´¢ç»“æœ)
    - è¾“å‡º: discovered_influencers (åšä¸»åˆ—è¡¨)
    """
    print("\n--- èŠ‚ç‚¹: åšä¸»æå–å™¨ (Node: Influencer Extractor) ---")

    # è·å– Web æœç´¢ç»“æœ
    web_results = state.leads
    if not web_results:
        print("âš ï¸ æ²¡æœ‰ Web æœç´¢ç»“æœï¼Œè·³è¿‡åšä¸»æå–")
        return {
            "discovered_influencers": [],
            "logs": state.logs + ["ã€åšä¸»æå–ã€‘è·³è¿‡: æ—  Web æœç´¢ç»“æœ"]
        }

    # å‡†å¤‡ä¸Šä¸‹æ–‡ï¼šæ±‡æ€»æ‰€æœ‰ Web æœç´¢ç»“æœ
    context_parts = []
    for idx, lead in enumerate(web_results, 1):
        context_parts.append(f"""
ã€æ–‡ç«  {idx}ã€‘
æ ‡é¢˜: {lead.title}
URL: {lead.url}
æ‘˜è¦: {lead.snippet}
æ ‡ç­¾: {', '.join(lead.tags) if lead.tags else 'æ— '}
        """.strip())

    context_str = "\n\n".join(context_parts)
    target_domains = ", ".join(state.target_domains) if state.target_domains else "æœªæŒ‡å®šé¢†åŸŸ"

    user_prompt = f"""
Role: You are an expert at extracting content creator information from articles.
Target Domain: {target_domains}

Article Data:
{context_str}

Task: Extract top content creators mentioned in these articles.

ğŸ”‘ **PLATFORM IDENTIFICATION STRATEGY** (åˆ†å±‚æå–):

## Tier 1: High Confidence (Preferred)
**Extract WITH platform fingerprint**:

1. **YouTube**:
   - âœ… "@channelname" (e.g., "@MKBHD")
   - âœ… "youtube.com/@handle"
   - âœ… "youtube.com/c/ChannelName"
   - â†’ `confidence="high"`

2. **Bilibili**:
   - âœ… "UID: 946974"
   - âœ… "space.bilibili.com/946974"
   - â†’ `confidence="high"`

## Tier 2: Medium Confidence (Acceptable) - â­ PRIORITIZE THIS TIER
**Extract name-only IF the creator is clearly recommended**:

**CRITICAL**: Most articles don't include @handles or UIDs! Extract the name anyway!

1. **YouTube**:
   - âš ï¸ "Two Minute Papers" (no @, but clearly a YouTube channel)
   - âš ï¸ "MKBHD" (well-known tech reviewer)
   - âš ï¸ "Corridor Digital" (production team)
   - â†’ `confidence="medium"`, `identifier=name`

2. **Bilibili**:
   - âš ï¸ "ææ°¸ä¹è€å¸ˆ" (famous science educator)
   - âš ï¸ "å½±è§†é£“é£" (well-known production team)
   - âš ï¸ "è€ç•ªèŒ„" (gaming creator)
   - â†’ `confidence="medium"`, `identifier=name`

**Requirements for Tier 2** (Looser requirements):
- Article mentions this creator in ANY positive context
- Name appears in article content (doesn't have to be in title)
- Clear indication this is a content creator (not article author)
- **NO need for @handle or UID** - we'll search by name later!

## Tier 3: Low Confidence (Extract but flag)
**Ambiguous cases**:
- Mentioned in passing
- Unclear if creator or subject
- â†’ `confidence="low"`, `identifier=name`

## DO NOT Extract:
- âŒ Article authors (unless article is about recommending creators)
- âŒ Random names without context
- âŒ Subjects of videos (not the creator)

## identifier Field Strategy:
```
if @handle or URL available:
    identifier = "@handle" or "URL"
    confidence = "high"
else if clear creator recommendation:
    identifier = name
    confidence = "medium"
else:
    identifier = name
    confidence = "low"
```

**Examples**:

âœ… Tier 1 (High Confidence):
```json
{{
  "name": "MKBHD",
  "platform": "youtube",
  "identifier": "@MKBHD",
  "confidence": "high"
}}
```

âœ… Tier 2 (Medium - Acceptable):
```json
{{
  "name": "Two Minute Papers",
  "platform": "youtube",
  "identifier": "Two Minute Papers",  // No @handle, but clearly recommended
  "confidence": "medium"
}}
```

âš ï¸ Tier 3 (Low - Extract but risky):
```json
{{
  "name": "Ken Jee",
  "platform": "youtube",
  "identifier": "Ken Jee",
  "confidence": "low"  // Might be irrelevant, but extract anyway
}}
```
â†’ Note: Low confidence will be deprioritized in task queue

âŒ DO NOT Extract:
```json
{{
  "name": "John Doe",  // Article author
  "platform": "youtube",
  "identifier": "John Doe",
  "confidence": "low"
}}
```
â†’ This is the article author, not a recommended creator

**Strategy** (In order of importance):
1. **MAXIMIZE Tier 2**: Most real articles don't have @handles - extract names aggressively!
2. Prefer Tier 1 (with @handle/UID) when available
3. Include Tier 3 for completeness (mark as low confidence)
4. Quality gate and search algorithms will filter bad results later

**Better to over-extract than under-extract** - The system can handle false positives via:
- Priority de-ranking (low confidence = priority 45 < keyword search priority 50)
- Quality gate filtering during search
- Deduplica if multiple sources mention same creator

**Common Mistake to Avoid**:
âŒ "No @handle found, skip this creator" â†’ TOO STRICT
âœ… "No @handle, but creator mentioned â†’ extract with medium/low confidence"

**Output**: Return InfluencerExtractorOutput with ALL discovered creators, even without handles.
    """

    try:
        result: InfluencerExtractorOutput = get_llm_with_schema(
            user_prompt=user_prompt,
            response_model=InfluencerExtractorOutput,
            capability="creative",  # ä½¿ç”¨ creative èƒ½åŠ›å¤„ç†é•¿ä¸Šä¸‹æ–‡
            system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿¡æ¯æå–ä¸“å®¶ï¼Œæ“…é•¿ä»æ–‡ç« ä¸­æå–åšä¸»å’Œå†…å®¹åˆ›ä½œè€…ä¿¡æ¯ã€‚

æ ¸å¿ƒåŸåˆ™: å®å¯å¤šæå–ä¹Ÿä¸è¦æ¼æ‰æœ‰ä»·å€¼çš„åˆ›ä½œè€…ï¼
- å³ä½¿æ²¡æœ‰@handleæˆ–UIDï¼Œåªè¦æ–‡ç« æåˆ°åˆ›ä½œè€…åå­—ï¼Œå°±åº”è¯¥æå–
- æ ‡è®°é€‚å½“çš„confidenceç­‰çº§ï¼Œè®©ä¸‹æ¸¸ç³»ç»Ÿå†³å®šæ˜¯å¦ä½¿ç”¨
- ä¸è¦å› ä¸ºä¿¡æ¯ä¸å®Œæ•´å°±è·³è¿‡æå–"""
        )

        # æŒ‰å¹³å°åˆ†ç»„ç»Ÿè®¡
        youtube_influencers = [i for i in result.influencers if i.platform == "youtube"]
        bilibili_influencers = [i for i in result.influencers if i.platform == "bilibili"]

        print(f"âœ… åšä¸»æå–: {len(result.influencers)} ä¸ª (YT:{len(youtube_influencers)} BL:{len(bilibili_influencers)})")

        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼šé«˜ç½®ä¿¡åº¦ > å¤šæ¬¡æåŠ > ä¸­ç½®ä¿¡åº¦ > ä½ç½®ä¿¡åº¦
        confidence_score = {"high": 3, "medium": 2, "low": 1}
        sorted_influencers = sorted(
            result.influencers,
            key=lambda x: (confidence_score.get(x.confidence, 1), x.mention_count),
            reverse=True
        )

        # ğŸ”‘ æ˜¾ç¤ºæå–åˆ°çš„åšä¸»è¯¦æƒ…ï¼ˆæ‰€æœ‰ï¼‰
        if sorted_influencers:
            print(f"\nğŸ“‹ æå–åˆ°çš„åšä¸»åˆ—è¡¨:")
            for idx, inf in enumerate(sorted_influencers, 1):
                identifier_str = inf.identifier if inf.identifier else "æ— identifier"
                print(f"   [{idx}] {inf.name} | {inf.platform} | {inf.confidence} | {identifier_str[:40]}")

        # ğŸ”‘ å…ˆè½¬æ¢ä¸ºå­—å…¸ï¼Œç„¶åå»é‡
        influencer_dicts_raw = [inf.model_dump() for inf in sorted_influencers]
        influencer_dicts = _deduplicate_influencers(influencer_dicts_raw)

        return {
            "discovered_influencers": influencer_dicts,
            "plan_status": "planning",  # ğŸ”‘ é‡ç½®çŠ¶æ€ï¼Œè®© Planner ç»§ç»­è§„åˆ’
            "logs": state.logs + [
                f"ã€åšä¸»æå–ã€‘å‘ç° {len(result.influencers)} ä¸ªåšä¸» (YouTube: {len(youtube_influencers)}, Bilibili: {len(bilibili_influencers)})"
            ]
        }

    except Exception as e:
        print(f"âŒ åšä¸»æå–å¤±è´¥: {e}")
        # å…œåº•ç­–ç•¥ï¼šè¿”å›ç©ºåˆ—è¡¨
        return {
            "discovered_influencers": [],
            "plan_status": "planning",  # ç»§ç»­è®© Planner è§„åˆ’
            "logs": state.logs + [f"ã€åšä¸»æå–ã€‘å¤±è´¥: {e}"]
        }


def _deduplicate_influencers(influencers: List) -> List:
    """å»é‡åšä¸»ï¼Œåˆå¹¶ç›¸åŒçš„"""
    deduped = {}
    for inf in influencers:
        identifier = inf.get("identifier", "").strip().lower() if inf.get("identifier") else inf.get("name", "").lower()
        key = f"{inf.get('platform')}:{identifier}"

        if key in deduped:
            # åˆå¹¶ï¼šç´¯åŠ æåŠæ¬¡æ•°ï¼Œä¿ç•™æœ€é«˜ç½®ä¿¡åº¦
            deduped[key]["mention_count"] += inf.get("mention_count", 1)
            if inf.get("confidence") == "high":
                deduped[key]["confidence"] = "high"
        else:
            deduped[key] = inf

    return list(deduped.values())
