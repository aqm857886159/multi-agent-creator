from datetime import datetime
from typing import Dict, Any, List
from pydantic import BaseModel, Field
from core.llm import ModelGateway
from core.state import RadarState
from tools.web_search import FirecrawlScout

# Define Schema for Discovery Plan
class DiscoveryPlan(BaseModel):
    platform_queries: Dict[str, str] = Field(description="Search queries for each platform (youtube, douyin, reddit)")
    search_keywords: List[str] = Field(description="List of 3-5 core sub-niche keywords")

# Define Schema for Extraction
class ExtractedSources(BaseModel):
    youtube_urls: List[str] = Field(default_factory=list)
    douyin_urls: List[str] = Field(default_factory=list)
    reddit_urls: List[str] = Field(default_factory=list)

def run_discovery(state: RadarState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹ 1: å…¨ç½‘ä¾¦å¯Ÿ (Discovery) - Structured Output Version
    """
    print("\n--- èŠ‚ç‚¹: å…¨ç½‘ä¾¦å¯Ÿ (Node 1: Discovery) ---")
    
    llm = ModelGateway()
    firecrawl = FirecrawlScout()
    
    domains = state.target_domains
    now = datetime.now()
    current_year = now.year
    
    user_prompt = f"""
    èƒŒæ™¯: æˆ‘éœ€è¦å»ºç«‹ä¸€ä¸ªé«˜è´¨é‡çš„ "{domains}" é¢†åŸŸæƒ…æŠ¥ç›‘æ§åº“ã€‚
    æ—¶é—´: {current_year} å¹´
    
    ä»»åŠ¡: 
    1. ä¸º YouTube, Douyin, Reddit åˆ†åˆ«ç”Ÿæˆä¸€ä¸ª"æ‰¾äºº/æ‰¾æ¦œå•"çš„æœç´¢æŸ¥è¯¢ã€‚
    2. æ‹†è§£ 3-5 ä¸ªçƒ­ç‚¹å­èµ›é“å…³é”®è¯ã€‚
    """
    
    try:
        print(f"ğŸ§  æ­£åœ¨ç­–åˆ’å…¨å¹³å°ä¾¦å¯Ÿæ–¹æ¡ˆ...")
        
        plan: DiscoveryPlan = llm.call_with_schema(
            user_prompt=user_prompt,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæƒ…æŠ¥åˆ†æå¸ˆã€‚",
            schema_model=DiscoveryPlan,
            capability="reasoning"
        )
        
        print(f"ğŸ”‘ ä¾¦å¯ŸæŒ‡ä»¤: {plan.platform_queries}")
        print(f"ğŸ”‘ æ ¸å¿ƒå…³é”®è¯: {plan.search_keywords}")
        
        for key in ["youtube", "douyin", "reddit"]:
            state.monitoring_list.setdefault(key, [])
            
        found_yt, found_dy, found_rd = [], [], []
        
        if firecrawl.api_key:
            # Execute searches
            for platform, query in plan.platform_queries.items():
                if not query: continue
                print(f"ğŸ•µï¸  æœç´¢ {platform}: '{query}'")
                try:
                    # Use the fixed search method (no params dict)
                    results = firecrawl.search_and_scrape(query, limit=1)
                    if results:
                        extracted = _extract_sources(llm, str(results), platform)
                        if platform == 'youtube': found_yt.extend(extracted.youtube_urls)
                        if platform == 'douyin': found_dy.extend(extracted.douyin_urls)
                        if platform == 'reddit': found_rd.extend(extracted.reddit_urls)
                except Exception as e:
                    print(f"  âš ï¸ {platform} æœç´¢å¤±è´¥: {e}")

            # Deduplicate and Merge
            new_yt = [u for u in found_yt if "youtube.com/" in u and u not in state.monitoring_list["youtube"]]
            state.monitoring_list["youtube"].extend(new_yt)
            
            new_dy = [u for u in found_dy if "douyin.com/" in u and u not in state.monitoring_list["douyin"]]
            state.monitoring_list["douyin"].extend(new_dy)
            
            new_rd = [u for u in found_rd if "reddit.com/r/" in u and u not in state.monitoring_list["reddit"]]
            state.monitoring_list["reddit"].extend(new_rd)
            
            print(f"âœ… ä¾¦å¯Ÿæˆ˜æœ: YT +{len(new_yt)}, DY +{len(new_dy)}, Reddit +{len(new_rd)}")
        
        return {
            "keywords": plan.search_keywords,
            "monitoring_list": state.monitoring_list,
            "logs": state.logs + [f"Discovery: YT+{len(found_yt)} DY+{len(found_dy)} RD+{len(found_rd)}"]
        }
        
    except Exception as e:
        print(f"âŒ ä¾¦å¯Ÿé˜¶æ®µå‡ºé”™: {e}")
        return {"logs": state.logs + [f"Discovery failed: {e}"]}

def _extract_sources(llm: ModelGateway, text_content: str, platform_hint: str) -> ExtractedSources:
    """è¾…åŠ©å‡½æ•°ï¼šè°ƒç”¨ LLM æå–é“¾æ¥ (Structured)"""
    prompt = f"""
    Context: Scraped search results for {platform_hint}.
    Goal: Extract valid profile URLs.
    Text: {text_content[:10000]}
    """
    try:
        return llm.call_with_schema(
            user_prompt=prompt,
            system_prompt="æ•°æ®æ¸…æ´—ä¸“å®¶ã€‚",
            schema_model=ExtractedSources,
            capability="fast"
        )
    except:
        return ExtractedSources()
