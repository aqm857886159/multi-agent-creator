from typing import Dict, Any, List, Optional, Tuple
from pydantic import BaseModel, Field
from core.state import RadarState
from core.llm import get_llm_with_schema
from core.tool_registry import registry
import json
from datetime import datetime

TARGET_TOTAL_ITEMS = 50  # æ”¶é›†50æ¡é«˜è´¨é‡å†…å®¹
MAX_PLAN_STEPS = 50  # å¢åŠ è§„åˆ’æ­¥æ•°é™åˆ¶ä»¥æ”¯æŒæ›´å¤šæ”¶é›†
DISCOVERY_QUERIES = []
DEFAULT_TOPICS = []
TOPIC_TEMPLATES = {}

class ToolCall(BaseModel):
    tool_name: str = Field(..., description="è°ƒç”¨çš„å·¥å…·åç§°")
    arguments: Dict[str, Any] = Field(..., description="å·¥å…·è°ƒç”¨å‚æ•°")
    reasoning: str = Field(..., description="ä¸ºä»€ä¹ˆç°åœ¨éœ€è¦è°ƒç”¨è¿™ä¸ªå·¥å…·")

class PlannerOutput(BaseModel):
    thought: str = Field(..., description="å¯¹å½“å‰æƒ…å†µçš„åˆ†æä»¥åŠä¸‹ä¸€æ­¥è®¡åˆ’")
    action: Optional[ToolCall] = Field(None, description="è¦æ‰§è¡Œçš„å·¥å…·è°ƒç”¨ã€‚å¦‚æœä»»åŠ¡å®Œæˆåˆ™ä¸º Nullã€‚")
    is_finished: bool = Field(False, description="æ˜¯å¦å·²æ”¶é›†åˆ°è¶³å¤Ÿçš„æ•°æ®")

def run_planner(state: RadarState) -> Dict[str, Any]:
    print("\n--- èŠ‚ç‚¹: è§„åˆ’å¤§è„‘ (Node: Planner) ---")

    # 1. Prepare Context
    tool_schemas = registry.list_tool_schemas()
    scratchpad = state.plan_scratchpad

    # è·å–å½“å‰æ—¥æœŸ
    today_str = datetime.now().strftime("%Y-%m-%d")
    current_year = datetime.now().strftime("%Y")
    current_month = datetime.now().strftime("%Y-%m")
    collected = len(state.candidates)

    # ğŸ”‘ å¢åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºå½“å‰çŠ¶æ€
    print(f"ğŸ“Š å½“å‰è¿›åº¦: å·²æ”¶é›† {collected}/{TARGET_TOTAL_ITEMS} æ¡")
    print(f"ğŸ“Š å¾…ç›‘æ§é˜Ÿåˆ—: YouTube={len(state.pending_monitors.get('youtube', []))}, "
          f"Bilibili={len(state.pending_monitors.get('bilibili', []))}")
    print(f"ğŸ“Š å·²ç›‘æ§æ•°é‡: YouTube={len(state.monitored_sources.get('youtube', []))}, "
          f"Bilibili={len(state.monitored_sources.get('bilibili', []))}")
    
    if len(state.plan_scratchpad) >= MAX_PLAN_STEPS:
        print("âš ï¸ è§„åˆ’è¾¾åˆ°å®‰å…¨ä¸Šé™ï¼Œæå‰è¿›å…¥ç­›é€‰ã€‚")
        return {
            "plan_status": "finished",
            "plan_scratchpad": state.plan_scratchpad,
            "pending_monitors": state.pending_monitors,
            "discovery_history": state.discovery_history
        }

    # ğŸ”‘ ä¿®å¤å…³é”®é—®é¢˜ 1: ä¼˜å…ˆæ£€æŸ¥æ•°é‡ï¼Œåœæ­¢æ¡ä»¶ä¼˜å…ˆçº§æœ€é«˜
    if collected >= TARGET_TOTAL_ITEMS:
        print(f"ğŸ§  è§„åˆ’å®Œæˆ: å·²æ”¶é›† {collected} æ¡ç´ æï¼Œå‡†å¤‡è¿›å…¥ç­›é€‰ã€‚")
        return {
            "plan_status": "finished",
            "plan_scratchpad": state.plan_scratchpad,
            "pending_monitors": state.pending_monitors,
            "discovery_history": state.discovery_history
        }

    # æ£€æŸ¥æ˜¯å¦æœ‰ç¡®å®šæ€§ä»»åŠ¡ï¼ˆå¾…ç›‘æ§é¢‘é“æˆ–çº¿ç´¢ï¼‰ï¼Œä½†è¦å—æ•°é‡é™åˆ¶
    deterministic_action = _deterministic_plan(state, today_str, current_year, current_month)
    if deterministic_action:
        tool_name, arguments, reasoning = deterministic_action
        print(f"ğŸ§  è§„åˆ’å™¨: {reasoning}")
        print(f"ğŸ‘‰ å†³ç­–: è°ƒç”¨ {tool_name}")
        action = ToolCall(tool_name=tool_name, arguments=arguments, reasoning=reasoning)
        state.plan_scratchpad.append({"tool_call": action.model_dump(), "timestamp": "now"})
        return {
            "plan_status": "executing",
            "plan_scratchpad": state.plan_scratchpad,
            "pending_monitors": state.pending_monitors,
            "discovery_history": state.discovery_history
        }

    # Summarize history
    history_text = ""
    if not scratchpad:
        history_text = "æš‚æ— è¡ŒåŠ¨è®°å½•ã€‚"
    else:
        for entry in scratchpad:
            if "tool_call" in entry:
                tc = entry["tool_call"]
                history_text += f"\n[æ€è€ƒ]: {tc.get('reasoning', '')}\n"
                history_text += f"[è¡ŒåŠ¨]: è°ƒç”¨ {tc['tool_name']} å‚æ•° {tc['arguments']}\n"
            if "tool_result" in entry:
                res = entry["tool_result"]
                history_text += f"[ç»“æœ]: {res.get('summary', '')} (çŠ¶æ€: {res.get('status')})\n"
                if res.get('error'):
                    history_text += f"[é”™è¯¯]: {res.get('error')}\n"

    target = ", ".join(state.target_domains) or ", ".join(state.keywords)

    # ğŸ”‘ æ£€æŸ¥åŒå¼•æ“é˜¶æ®µ
    has_discovery_queries = len(state.discovery_queries) > 0
    has_web_results = len(state.leads) > 0
    has_influencers = len(state.discovered_influencers) > 0

    user_prompt = f"""
    ç›®æ ‡: ä¸ºä¸»é¢˜ '{target}' æ”¶é›†é«˜è´¨é‡å†…å®¹ã€‚
    å½“å‰æ—¥æœŸ: {today_str} (YYYY-MM-DD)
    å½“å‰å·²æ”¶é›†: {collected} æ¡ï¼Œç›®æ ‡è‡³å°‘ {TARGET_TOTAL_ITEMS} æ¡ã€‚

    å¯ç”¨å·¥å…·:
    {json.dumps(tool_schemas, indent=2, ensure_ascii=False)}

    æ‰§è¡Œå†å²:
    {history_text}

    ğŸ”‘ **åŒå¼•æ“ç­–ç•¥çŠ¶æ€**:
    - å‘ç°åšä¸»æœç´¢è¯å·²è®¾è®¡: {"æ˜¯" if has_discovery_queries else "å¦"}
    - Web æœç´¢å·²æ‰§è¡Œ: {"æ˜¯" if has_web_results else "å¦"}
    - åšä¸»å·²æå–: {"æ˜¯" if has_influencers else "å¦"}

    {"ğŸ“‹ å‘ç°åšä¸»æœç´¢è¯: " + str(state.discovery_queries[:3]) + ("..." if len(state.discovery_queries) > 3 else "") if has_discovery_queries else ""}
    {"ğŸ“‹ å·²å‘ç°åšä¸»æ•°é‡: " + str(len(state.discovered_influencers)) if has_influencers else ""}

    **å…³é”®ç­–ç•¥**:
    1. **åŒå¼•æ“æ‰§è¡Œé¡ºåº** â­â­â­ æœ€é‡è¦ï¼š
       å¦‚æœåˆšå¼€å§‹ï¼Œå¿…é¡»æŒ‰ä»¥ä¸‹é¡ºåºæ‰§è¡Œï¼š

       ã€é˜¶æ®µ 1: å‘ç°åšä¸»ã€‘
       a) å¦‚æœ discovery_queries å·²è®¾è®¡ä½† Web æœç´¢æœªæ‰§è¡Œï¼š
          â†’ **ç«‹å³ä½¿ç”¨ web_search æœç´¢ discovery_queries ä¸­çš„ç¬¬ä¸€ä¸ªå…³é”®è¯**
          â†’ ç›®çš„ï¼šæ‰¾åˆ°"åšä¸»æ¨èæ–‡ç« "ï¼ˆå¦‚"2025å¹´é¡¶çº§AIåšä¸»"ï¼‰
          â†’ ç¤ºä¾‹è°ƒç”¨ï¼š
             {{"tool_name": "web_search", "arguments": {{"query": "{state.discovery_queries[0] if state.discovery_queries else 'AIåšä¸»æ¨è'}", "limit": 10}}}}

       b) å¦‚æœ Web æœç´¢å·²å®Œæˆä½†åšä¸»æœªæå–ï¼š
          â†’ ç­‰å¾… influencer_extractor èŠ‚ç‚¹è‡ªåŠ¨æ‰§è¡Œï¼ˆä¸è¦è‡ªå·±è°ƒç”¨ï¼‰

       c) å¦‚æœåšä¸»å·²æå–ï¼š
          â†’ è¿›å…¥é˜¶æ®µ 2

       ã€é˜¶æ®µ 2: å†…å®¹æ”¶é›†ã€‘
       d) åšä¸»å‘ç°å®Œæˆåï¼Œæ‰æ‰§è¡Œ youtube_search / bilibili_search
       e) æˆ–è€…å¦‚æœæ²¡æœ‰å‘ç°åšä¸»ï¼ˆWebæœç´¢å¤±è´¥ï¼‰ï¼Œä¹Ÿå¯ä»¥ç›´æ¥æ‰§è¡Œå†…å®¹æœç´¢

    2. **æœç´¢ç­–ç•¥ (Time-Aware)**:
       - **å¿…é¡»**åœ¨å…³é”®è¯ä¸­åŠ å…¥æ—¥æœŸé™å®šï¼Œä»¥ç¡®ä¿å†…å®¹çš„æ—¶æ•ˆæ€§ã€‚
       - æ ¼å¼ç¤ºä¾‹: "AI News {current_month}", "Python tutorial {current_year}", "Latest tech reviews {today_str}"
       - å¦‚æœå¤§è¯æœç´¢æ— æ•ˆï¼Œå°è¯•æ›´å…·ä½“çš„æ—¶é—´èŒƒå›´æˆ–è¯é¢˜ï¼Œä¾‹å¦‚ "DeepSeek V3 analysis {current_month}"ã€‚
       - **åˆ‡å‹¿**åå¤æœç´¢åŒä¸€ä¸ªæ— æ•ˆçš„å¤§è¯ã€‚

    2. **è¯­è¨€ç­–ç•¥**:
       - ä½ çš„ç›®æ ‡å—ä¼—æ˜¯ä¸­æ–‡ç”¨æˆ·ï¼Œéœ€è¦åŒæ—¶è¦†ç›–ä¸­è‹±æ–‡å¹³å°ã€‚
       - **YouTube/Reddit**: ä½¿ç”¨è‹±æ–‡å…³é”®è¯æœç´¢ï¼ˆå¦‚ "AI News", "Python tutorial"ï¼‰
       - **Bilibili**: ä½¿ç”¨ä¸­æ–‡å…³é”®è¯æœç´¢ï¼ˆå¦‚ "AIæ–°é—»", "Pythonæ•™ç¨‹"ï¼‰

    3. **å¹³å°å¹³è¡¡ç­–ç•¥** â­ éå¸¸é‡è¦ï¼š
       - **å¿…é¡»åŒæ—¶å°è¯• YouTube å’Œ Bilibili ä¸¤ä¸ªå¹³å°**ï¼Œä¸è¦åªä¾èµ–ä¸€ä¸ª
       - ä¼˜å…ˆé¡ºåºï¼šå…ˆæ‰§è¡Œå¹¿æ³›æœç´¢ï¼ˆyoutube_search, bilibili_searchï¼‰ï¼Œå†è€ƒè™‘ç›‘æ§
       - å¦‚æœå·²ç»æ‰§è¡Œäº† youtube_searchï¼Œä¸‹ä¸€æ­¥åº”è¯¥æ‰§è¡Œ bilibili_search ä»¥ä¿æŒå¹³è¡¡
       - ä¸è¦è®© pending_monitors é˜Ÿåˆ—"ç»‘æ¶"ä½ çš„å†³ç­–ï¼Œå…ˆå®Œæˆå¹³å°è¦†ç›–

    4. **å·¥å…·é€‰æ‹©**:
       - å¦‚æœæŸä¸ªå·¥å…·å¤±è´¥äº†ï¼Œå°è¯•åˆ‡æ¢åˆ°å…¶ä»–å¹³å°
       - ä¸è¦æ­»ç£•ä¸€ä¸ªå¹³å°
    
    æŒ‡ä»¤:
    1. åˆ†æå†å²è®°å½•ã€‚å¦‚æœä½ å·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„å†…å®¹ï¼ˆè‡³å°‘ 5-10 æ¡é«˜è´¨é‡æ¡ç›®ï¼‰ï¼Œè®¾ç½® is_finished=Trueã€‚
    2. å¦‚æœæŸä¸ªå·¥å…·å¤±è´¥äº†ï¼Œå°è¯•ä½¿ç”¨ä¸åŒçš„å‚æ•°ï¼Œæˆ–è€…åˆ‡æ¢åˆ°å¤‡ç”¨å·¥å…·ï¼ˆä¾‹å¦‚ï¼šå¦‚æœ youtube_search å¤±è´¥ï¼Œå°è¯• web_searchï¼‰ã€‚
    3. åˆšå¼€å§‹æ—¶ï¼Œä¼˜å…ˆä½¿ç”¨å¹¿æ³›æœç´¢ï¼ˆå¦‚ youtube_search, reddit_search, web_searchï¼‰ï¼Œç„¶åå†æ·±å…¥æŒ–æ˜ã€‚
    4. ä¸è¦é‡å¤æ‰§è¡Œå·²ç»æˆåŠŸçš„ç›¸åŒå·¥å…·è°ƒç”¨ã€‚
    5. å¦‚æœå‘ç°éœ€è¦ç™»å½•ä½†æœªç™»å½•çš„å·¥å…·æŠ¥é”™ï¼Œè¯·å°è¯•å…¶ä»–æ— éœ€ç™»å½•çš„å·¥å…·ã€‚
    
    è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºä½ çš„è®¡åˆ’ã€‚
    """
    
    try:
        # Use reasoning capability for planning
        plan: PlannerOutput = get_llm_with_schema(
            user_prompt=user_prompt,
            response_model=PlannerOutput,
            capability="reasoning",
            system_prompt=f"ä½ æ˜¯ä¸€ä¸ªè‡ªä¸»è°ƒç ”æ™ºèƒ½ä½“ã€‚å½“å‰æ—¶é—´æ˜¯ {today_str}ã€‚è¯·è§„åˆ’ä¸‹ä¸€æ­¥è¡ŒåŠ¨ä»¥æ”¶é›†æƒ…æŠ¥ã€‚"
        )
        
        if plan.is_finished:
            print(f"ğŸ§  è§„åˆ’å®Œæˆ: {plan.thought}")
            return {
                "plan_status": "finished",
                "plan_scratchpad": state.plan_scratchpad,
                "pending_monitors": state.pending_monitors,
                "discovery_history": state.discovery_history
            }
        
        if plan.action:
            print(f"ğŸ§  æ€è€ƒ: {plan.thought}")
            print(f"ğŸ‘‰ å†³ç­–: è°ƒç”¨ {plan.action.tool_name}")
            
            # Add to scratchpad
            new_entry = {
                "tool_call": plan.action.model_dump(),
                "timestamp": "now" # proper timestamp in real app
            }
            state.plan_scratchpad.append(new_entry)
            
            return {
                "plan_status": "executing", 
                "plan_scratchpad": state.plan_scratchpad,
                "pending_monitors": state.pending_monitors,
                "discovery_history": state.discovery_history
            }
            
        # Fallback
        return {
            "plan_status": "finished",
            "plan_scratchpad": state.plan_scratchpad,
            "pending_monitors": state.pending_monitors,
            "discovery_history": state.discovery_history
        }
        
    except Exception as e:
        print(f"âŒ Planner Error: {e}")
        # Fail safe: finish to avoid loops
        return {
            "plan_status": "finished",
            "plan_scratchpad": state.plan_scratchpad,
            "pending_monitors": state.pending_monitors,
            "discovery_history": state.discovery_history
        }

def _deterministic_plan(state: RadarState, today: str, year: str, month: str) -> Optional[Tuple[str, Dict[str, Any], str]]:
    """
    ğŸ”‘ ç¡®å®šæ€§è§„åˆ’é€»è¾‘ - åŒå¼•æ“ç­–ç•¥

    æ‰§è¡Œé¡ºåºï¼š
    1. é¡ºè—¤æ‘¸ç“œï¼šæœç´¢å·²å‘ç°çš„åšä¸»å†…å®¹ï¼ˆå¼•æ“ 1 çš„æ ¸å¿ƒï¼‰
    2. çº¿ç´¢è·Ÿè¿›ï¼šè·Ÿè¿› Web æœç´¢å‘ç°çš„çº¿ç´¢
    3. ç›‘æ§æ‰§è¡Œï¼šç›‘æ§å¾…ç›‘æ§é˜Ÿåˆ—ä¸­çš„é¢‘é“ï¼ˆå¼•æ“ 1 çš„æŒç»­ç›‘æ§ï¼‰

    æ³¨æ„ï¼šåªæœ‰ä¸¤ä¸ªå¹³å°éƒ½æœç´¢è¿‡åï¼Œæ‰æ‰§è¡Œç›‘æ§ï¼ˆé¿å…è¢«"ç»‘æ¶"ï¼‰
    """

    # ğŸ†• ä¼˜å…ˆçº§ 1: é¡ºè—¤æ‘¸ç“œ - æœç´¢å·²å‘ç°çš„åšä¸»å†…å®¹
    influencer_action = _schedule_influencer_search(state, today, year, month)
    if influencer_action:
        return influencer_action

    # ğŸ”‘ ä¿®å¤å…³é”®é—®é¢˜ï¼šåªåœ¨æœç´¢é˜¶æ®µå®Œæˆåæ‰æ‰§è¡Œç›‘æ§
    # æ£€æŸ¥æ˜¯å¦ä¸¤ä¸ªå¹³å°éƒ½æœç´¢è¿‡äº†
    youtube_searched = state.platform_search_progress.get("youtube", False)
    bilibili_searched = state.platform_search_progress.get("bilibili", False)

    # å¦‚æœè¿˜æ²¡æœ‰å®Œæˆå¹³å°æœç´¢ï¼Œä¸æ‰§è¡Œç›‘æ§ï¼ˆé¿å…è¢«"ç»‘æ¶"ï¼‰
    if not (youtube_searched and bilibili_searched):
        return None

    # ä¼˜å…ˆçº§ 2: çº¿ç´¢è·Ÿè¿›
    lead_action = _schedule_lead_follow_up(state)
    if lead_action:
        return lead_action

    # ä¼˜å…ˆçº§ 3: ç›‘æ§æ‰§è¡Œ
    action = _schedule_pending_monitor(state)
    if action:
        return action
    return None

AUTO_MONITOR_LIMIT = 2


def _schedule_influencer_search(state: RadarState, today: str, year: str, month: str) -> Optional[Tuple[str, Dict[str, Any], str]]:
    """
    ğŸ†• é¡ºè—¤æ‘¸ç“œï¼šé’ˆå¯¹å‘ç°çš„åšä¸»è¿›è¡Œæœç´¢ï¼ˆå¼•æ“ 1 çš„æ ¸å¿ƒé€»è¾‘ï¼‰

    æµç¨‹ï¼š
    1. ä» discovered_influencers ä¸­æ‰¾åˆ°æœªæœç´¢çš„åšä¸»
    2. æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆé«˜ç½®ä¿¡åº¦ + å¤šæ¬¡æåŠï¼‰
    3. ç”Ÿæˆé’ˆå¯¹æ€§æœç´¢ä»»åŠ¡
    4. æ ‡è®°ä¸ºå·²æœç´¢
    """
    if not state.discovered_influencers:
        return None

    # æŒ‰ä¼˜å…ˆçº§æ’åº
    confidence_score = {"high": 3, "medium": 2, "low": 1}
    sorted_influencers = sorted(
        state.discovered_influencers,
        key=lambda x: (confidence_score.get(x.confidence, 1), x.mention_count),
        reverse=True
    )

    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœªæœç´¢çš„åšä¸»
    for influencer in sorted_influencers:
        if influencer.identifier in state.searched_influencers:
            continue

        # æ‰¾åˆ°äº†æœªæœç´¢çš„åšä¸»
        target_domain = state.target_domains[0] if state.target_domains else ""

        if influencer.platform == "youtube":
            tool_name = "youtube_search"
            keyword = f"{influencer.name} {target_domain}".strip()
            reasoning = f"é¡ºè—¤æ‘¸ç“œï¼šæœç´¢é¡¶çº§åšä¸» {influencer.name} çš„ {target_domain} ç›¸å…³å†…å®¹"

            # æ ‡è®°ä¸ºå·²æœç´¢
            state.searched_influencers.append(influencer.identifier)

            return (
                tool_name,
                {
                    "keyword": keyword,
                    "limit": 8
                },
                reasoning
            )

        elif influencer.platform == "bilibili":
            tool_name = "bilibili_search"
            keyword = f"{influencer.name} {target_domain}".strip()
            reasoning = f"é¡ºè—¤æ‘¸ç“œï¼šæœç´¢é¡¶çº§UPä¸» {influencer.name} çš„ {target_domain} ç›¸å…³å†…å®¹"

            # æ ‡è®°ä¸ºå·²æœç´¢
            state.searched_influencers.append(influencer.identifier)

            return (
                tool_name,
                {
                    "keyword": keyword,
                    "limit": 8
                },
                reasoning
            )

    # æ‰€æœ‰åšä¸»éƒ½æœç´¢å®Œäº†
    if not state.influencer_search_done:
        state.influencer_search_done = True
        print("âœ… åšä¸»æœç´¢é˜¶æ®µå®Œæˆï¼Œæ‰€æœ‰å‘ç°çš„åšä¸»å†…å®¹å·²æœç´¢")

    return None


def _schedule_pending_monitor(state: RadarState) -> Optional[Tuple[str, Dict[str, Any], str]]:
    priorities = [
        ("youtube", "youtube_monitor", "channel_url", "æ‰§è¡Œé¢‘é“ç›‘æ§ï¼š{target}"),
        ("bilibili", "bilibili_monitor", "user_id", "ç›‘æ§ Bç«™ UPä¸»ï¼š{target}")
    ]
    for platform, tool_name, arg_key, template in priorities:
        pending = state.pending_monitors.get(platform, [])
        autoruns = state.monitor_autoruns.get(platform, 0)
        if pending and autoruns < AUTO_MONITOR_LIMIT:
            target = pending.pop(0)
            args = {arg_key: target}
            reasoning = template.format(target=target)
            state.monitor_autoruns[platform] = autoruns + 1
            return tool_name, args, reasoning
    return None


def _schedule_lead_follow_up(state: RadarState) -> Optional[Tuple[str, Dict[str, Any], str]]:
    if not state.leads:
        return None

    priority_platforms = state.session_focus.get("priority_platforms") or [
        "youtube", "bilibili"
    ]

    for idx, lead in enumerate(state.leads):
        keyword = _select_lead_keyword(lead)
        if not keyword:
            continue

        platform = _detect_lead_platform(lead, priority_platforms)
        tool_name = _platform_search_tool(platform)
        if not tool_name:
            continue

        state.leads.pop(idx)
        state.logs.append(f"ã€çº¿ç´¢ã€‘è·Ÿè¿› {platform} æœç´¢ {keyword}")
        reasoning = f"çº¿ç´¢ã€Š{lead.title}ã€‹æç¤º {platform} æœ‰ç›¸å…³å†…å®¹ï¼Œå°è¯•å…³é”®è¯: {keyword}"
        arguments = {
            "keyword": keyword,
            "limit": 8,
            "topic_hint": lead.topic_hint
        }
        return tool_name, arguments, reasoning

    return None


def _detect_lead_platform(lead, priority_platforms: List[str]) -> str:
    url = (lead.url or "").lower()
    platform_markers = {
        "bilibili": ["bilibili.com", "bç«™"],
        "youtube": ["youtube.com", "youtu.be"]
    }

    for platform, markers in platform_markers.items():
        if any(marker in url for marker in markers):
            return platform

    for tag in lead.tags:
        low = tag.lower()
        for platform, markers in platform_markers.items():
            if any(marker in low for marker in markers):
                return platform

    return (priority_platforms or ["bilibili"])[0]


def _platform_search_tool(platform: str) -> Optional[str]:
    mapping = {
        "bilibili": "bilibili_search",
        "youtube": "youtube_search"
    }
    return mapping.get(platform)


def _select_lead_keyword(lead) -> str:
    for tag in lead.tags:
        clean = tag.strip()
        if clean:
            return clean[:60]
    title = (lead.title or "").strip()
    if title:
        return title[:60]
    return ""


def _schedule_initial_platform_search(state: RadarState) -> Optional[Tuple[str, Dict[str, Any], str]]:
    return None
